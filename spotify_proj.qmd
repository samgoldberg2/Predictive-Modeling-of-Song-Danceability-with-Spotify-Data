---
author: "Sam Goldberg (shg59)"
date: today
format: pdf
editor: visual
execute:
  warning: false
  cache: true
---

# Setup

Load packages and data:

```{r}
#| label: load-packages
#| cache: false
# label: load-packages
# cache: false

library(tidyverse)
library(tidymodels)
```

```{r}
#| label: null-model-danceable
# label: null-model-danceable

# add code here
spotify_train <- readRDS('data/spotify-train.rds')
spotify_test <- readRDS('data/spotify-test.rds')

set.seed(100)

spotify_folds <- vfold_cv(data = spotify_train, v = 10, 
                          strata = danceability)

 null_spotify_spec <- null_model() |>
   set_engine("parsnip") |> 
   set_mode("classification") |> 
   translate()
 
 null_spotify_fit <- null_spotify_spec |>
   fit_resamples(
     preprocessor = danceability ~ .,
     resamples = spotify_folds) |>
   collect_metrics()

null_spotify_fit
```

The accuracy for this model is 0.5661698 while the roc_auc is 0.50000. With a roc_auc of 0.5, the null model performs poorly. This model is worthless, as it is just random guessing.


```{r}
#| label: logistic-regression-model
# label: logistic-regression-model

# add code here

set.seed(100)

spotify_lr_recipe <- recipe(danceability ~ energy + liveness + 
                              loudness + speechiness + tempo, 
                            data = spotify_train) |>
  step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_numeric_predictors())

log_spotify_spec <- logistic_reg() |>
set_engine("glm")

spotify_lr_wf <- workflow() |>
add_recipe(spotify_lr_recipe) |>
add_model(log_spotify_spec)

lr_spotify_fit <- spotify_lr_wf |>
fit_resamples(
resamples = spotify_folds,
control = ctrl_grid
) |>
collect_metrics()

lr_spotify_fit
```

For my predictor variables, I chose energy, liveness, loudness, speechiness, and tempo since I believe these are all factors that have a direct correlation with the danceability of songs. The accuracy for the logistic regression model is 0.6830789 while the roc_auc is 0.7391180. With a roc_auc slightly above 0.7, this model performs decently.


```{r}
#| label: spotify-decision-tree
# label: spotify-decision-tree

# add code here

set.seed(100)

spotify_tree_recipe <- recipe(danceability ~ energy + liveness + 
                              loudness + speechiness + tempo, 
                            data = spotify_train) |>
  step_normalize(all_numeric_predictors(), -all_outcomes()) |>
  step_dummy(all_nominal_predictors(), -all_outcomes())

spotify_tree_mod <- decision_tree() |>
  set_mode("classification") |>
  set_engine("rpart")

spotify_tree_grid <- grid_regular(min_n(), levels = 10)

spotify_tree_wf <- workflow() |>
  add_model(spotify_tree_mod) |>
  add_recipe(spotify_tree_recipe)

spotify_tree_res <- tune_grid(spotify_tree_wf, resamples = spotify_folds, 
                      grid = spotify_tree_grid)

spotify_tree_metrics <- spotify_tree_res |>
  collect_metrics()

spotify_tree_metrics
```

For the decision tree model, I normalized all numeric predictors and then used step_dummy() on all nominal predictors. The model I used is a decision tree, and I set the engine to rpart and the mode to classification since danceability has a binary outcome. I then tuned the min_n hyperparameter and collected the metrics to observe the accuracy and ROC AUC. The accuracy for the decision tree model is 0.7213433 while the roc_auc is 0.7259212. With a roc_auc slightly above 0.7, this model performs decently.

```{r}
#| label: spotify-random-forest
# label: spotify-random-forest

set.seed(100)

spotify_rf_recipe <- recipe(danceability ~ energy + liveness + 
                              loudness + speechiness + tempo, 
                            data = spotify_train) |>
  step_impute_median(all_numeric_predictors()) |>
  step_impute_mode(all_nominal_predictors()) |>
  step_naomit(all_outcomes()) 

spotify_rf_mod <- rand_forest(mtry = tune(), min_n = tune()) |>
  set_mode("classification") |>
  set_engine("ranger")

spotify_rf_wf <- workflow() |>
  add_model(spotify_rf_mod) |>
  add_recipe(spotify_rf_recipe)

spotify_rf_tune <- spotify_rf_wf |>
  tune_grid(resamples = spotify_folds, grid = 10, 
            control = ctrl_grid)

spotify_rf_tune |>
  show_best()

spotify_rf_tune |>
  autoplot()
```

For the random forest model, I utilized median and modal imputation to replace missing values in the energy, liveness, loudness, speechiness, liveness, and tempo columns with their medians. Additionally, I used the ranger engine for the random forest model and the classification mode since we are predicting danceability, which has a binary outcome. I used the tune_grid() function to perform hyperparameter tuning. This involves training models with different combinations of hyperparameters and seeing which combination has the highest ROC AUC. The highest ROC AUC for this model is 0.8219402, which is the best performance yet. This occurs at mtry = 1 and min_n = 7. With a roc_auc above 0.8, this model is considered good!

```{r}
#| label: spotify-k-nearest-neighbors
# label: spotify-k-nearest-neighbors

set.seed(100)

spotify_knn_recipe <- recipe(danceability ~ energy + liveness + 
                              loudness + speechiness + tempo, 
                            data = spotify_train) |>
  step_impute_median(all_numeric_predictors()) |>
  step_impute_mode(all_nominal_predictors()) |>
  step_naomit(all_outcomes()) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors())

spotify_knn_mod <- nearest_neighbor() |>
  set_mode("classification") |>
  set_engine("kknn")

spotify_knn_grid <- grid_regular(neighbors(), levels = 10)

spotify_knn_wf <- workflow() |>
  add_model(spotify_knn_mod) |>
  add_recipe(spotify_knn_recipe)

spotify_knn_tune <- spotify_knn_wf |>
  tune_grid(spotify_knn_wf, resamples = spotify_folds, grid = spotify_knn_grid)

spotify_knn_metrics <- spotify_knn_tune |>
  collect_metrics() 

spotify_knn_metrics

```

For the k-nearest neighbor model, I know that it requires all numeric predictors, and all need to be centered and scaled. I used step_dummy() to convert nominal data into numeric dummy variables, which was needed as predictors. I used step_novel() since it "adds a catch-all level to a factor for any new values not encountered in model training, which lets R intelligently predict new levels in the test set" (Soltoff Better training data lecture). I also used step_zv() to handle zero variance variables. I normalized all numeric predictors and then used step_dummy() on all nominal predictors and then utilized median and modal imputation to replace missing values in the energy, liveness, loudness, speechiness, liveness, and tempo columns. I used kknn as the engine and tuned the neighbors() hyperparameter, which determines the number of neighbors to consider when making predictions. The accuracy for the k-nearest neighbor model is 0.708430 while the roc_auc is 0.756437. With a roc_auc halfway between 0.7 and 0.8, this model performs pretty decently.

```{r}
#| label: spotify-ridge-logistic-regression
# label: spotify-ridge-logistic-regression

set.seed(100)

spotify_ridge_mod <- logistic_reg(penalty = tune(), mixture = tune()) |>
  set_mode("classification") |>
  set_engine("glmnet")

spotify_ridge_grid <- expand_grid(
penalty = 10^seq(-6, -1, length.out = 20),
mixture = c(0, 0.2, 0.4, 0.6, 0.8, 1)
)

spotify_ridge_wf <- workflow() |>
  add_model(spotify_ridge_mod) |>
  add_recipe(spotify_knn_recipe)

spotify_ridge_tune <- tune_grid(spotify_ridge_wf, resamples = spotify_folds, 
                        grid = spotify_ridge_grid)

spotify_ridge_tune |>
  show_best()

spotify_ridge_tune |>
  autoplot()
```

For the ridge logistic regression model, I used the same recipe as the k-nearest neighbor model. I used glmnet as the engine and tuned the penalty and mixture hyperparameters. I tested the penalty parameter at the values 10\^seq(-6, -1, length.out = 20), and tested the mixture parameter at the values c(0, 0.2, 0.4, 0.6, 0.8, 1). The highest roc_auc for this model is 0.7386556, indicating a decent performance.


```{r}
#| label: spotify-final-predictive-model
# label: spotify-final-predictive-model

# add code here
spotify_rf_mod_final <- rand_forest(mtry = 1, min_n = 7) |>
  set_mode("classification") |>
  set_engine("ranger")

spotify_rf_wf_final <- workflow() |>
  add_model(spotify_rf_mod_final) |>
  add_recipe(spotify_rf_recipe)

spotify_rf_fit_final <- spotify_rf_wf_final |> 
  fit(data = spotify_train)

bind_cols(
spotify_test,
predict(spotify_rf_fit_final, new_data = spotify_test)
) |>
select(.id, starts_with(".pred")) |>
write_csv(file = "data/spotify-preds.csv")
```

I chose the random model because it performed the best in terms of ROC AUC during the cross-validation process. With the hyperparameters set to the optimal levels, this model performs the best in terms of predicting danceability.
